# ğŸ¤– AI Integration Architecture - MomFood Production Platform

## **AI Strategy Overview**

This document outlines the comprehensive artificial intelligence and machine learning architecture for transforming MomFood into an intelligent, data-driven food delivery platform that leverages AI to optimize operations, enhance user experience, and drive business growth.

## **AI Components Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        AI Service Layer                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Recommendation â”‚   Route         â”‚  Menu           â”‚  Chat     â”‚
â”‚    Engine       â”‚ Optimization    â”‚ Optimization    â”‚   Bot     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Demand        â”‚   Fraud         â”‚  Price          â”‚  Voice    â”‚
â”‚  Prediction     â”‚  Detection      â”‚ Optimization    â”‚ Assistant â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ML Pipeline Layer                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Data          â”‚   Feature       â”‚    Model        â”‚   Model   â”‚
â”‚ Preprocessing   â”‚  Engineering    â”‚   Training      â”‚ Serving   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Data Layer                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   User          â”‚   Order         â”‚  Restaurant     â”‚ External  â”‚
â”‚  Behavior       â”‚   History       â”‚    Data         â”‚   APIs    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## **1. Recommendation Engine**

### **Architecture Overview**

The recommendation engine combines multiple ML techniques to provide personalized suggestions for customers, restaurants, and drivers.

### **Hybrid Recommendation System**

```python
# Main recommendation engine architecture
class MomFoodRecommendationEngine:
    def __init__(self):
        self.collaborative_filter = CollaborativeFilteringModel()
        self.content_based = ContentBasedModel()
        self.deep_learning = DeepRecommendationModel()
        self.context_aware = ContextAwareModel()
        self.ensemble = EnsembleModel()
        
    def get_recommendations(self, user_id, context=None, num_recommendations=10):
        """
        Get hybrid recommendations combining multiple models
        """
        # Get recommendations from each model
        collab_recs = self.collaborative_filter.predict(user_id)
        content_recs = self.content_based.predict(user_id)
        deep_recs = self.deep_learning.predict(user_id)
        context_recs = self.context_aware.predict(user_id, context)
        
        # Ensemble predictions
        final_recs = self.ensemble.combine_predictions([
            collab_recs, content_recs, deep_recs, context_recs
        ])
        
        return final_recs[:num_recommendations]
```

### **Collaborative Filtering Model**

```python
import numpy as np
from scipy.sparse import csr_matrix
from sklearn.metrics.pairwise import cosine_similarity
import implicit

class CollaborativeFilteringModel:
    def __init__(self):
        self.model = implicit.als.AlternatingLeastSquares(
            factors=100,
            regularization=0.01,
            iterations=50,
            alpha=40
        )
        self.user_item_matrix = None
        self.item_features = None
        
    def prepare_data(self, orders_df):
        """
        Prepare user-item interaction matrix from order data
        """
        # Create user-item matrix with ratings based on:
        # - Order frequency
        # - Rating given
        # - Order value
        # - Recency
        
        user_item_data = []
        for _, order in orders_df.iterrows():
            rating = self._calculate_implicit_rating(order)
            user_item_data.append([
                order['customer_id'], 
                order['menu_item_id'], 
                rating
            ])
        
        # Convert to sparse matrix
        users = [item[0] for item in user_item_data]
        items = [item[1] for item in user_item_data]
        ratings = [item[2] for item in user_item_data]
        
        self.user_item_matrix = csr_matrix(
            (ratings, (users, items))
        )
        
    def _calculate_implicit_rating(self, order):
        """
        Calculate implicit rating from order data
        """
        base_score = 1.0
        
        # Boost for explicit ratings
        if order.get('rating'):
            base_score *= (order['rating'] / 5.0)
            
        # Boost for order value
        if order['total_amount'] > 50:
            base_score *= 1.2
            
        # Boost for recent orders
        days_ago = (datetime.now() - order['created_at']).days
        recency_factor = max(0.1, 1.0 - (days_ago / 365))
        base_score *= recency_factor
        
        # Boost for repeat orders of same item
        if order.get('repeat_order'):
            base_score *= 1.5
            
        return min(base_score, 5.0)
    
    def train(self):
        """
        Train the ALS model
        """
        self.model.fit(self.user_item_matrix)
        
    def predict(self, user_id, num_items=50):
        """
        Get recommendations for a user
        """
        try:
            user_index = self.user_mapping[user_id]
            item_ids, scores = self.model.recommend(
                user_index, 
                self.user_item_matrix[user_index],
                N=num_items,
                filter_already_liked_items=True
            )
            
            recommendations = []
            for item_idx, score in zip(item_ids, scores):
                item_id = self.reverse_item_mapping[item_idx]
                recommendations.append({
                    'item_id': item_id,
                    'score': float(score),
                    'type': 'collaborative'
                })
                
            return recommendations
        except KeyError:
            # Cold start problem - return popular items
            return self._get_popular_items(num_items)
```

### **Content-Based Model**

```python
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import pandas as pd

class ContentBasedModel:
    def __init__(self):
        self.tfidf_vectorizer = TfidfVectorizer(
            max_features=1000,
            stop_words='english',
            ngram_range=(1, 2)
        )
        self.item_features = None
        self.similarity_matrix = None
        
    def prepare_features(self, menu_items_df, restaurants_df):
        """
        Prepare content features for menu items
        """
        # Combine textual features
        features = []
        for _, item in menu_items_df.iterrows():
            restaurant = restaurants_df[
                restaurants_df['id'] == item['restaurant_id']
            ].iloc[0]
            
            # Combine features
            content = ' '.join([
                item.get('name', ''),
                item.get('description', ''),
                item.get('cuisine_type', ''),
                restaurant.get('cuisine_type', ''),
                ' '.join(item.get('ingredients', [])),
                ' '.join(item.get('dietary_flags', []))
            ])
            features.append(content)
            
        # Create TF-IDF matrix
        self.item_features = self.tfidf_vectorizer.fit_transform(features)
        self.similarity_matrix = cosine_similarity(self.item_features)
        
    def predict(self, user_id, user_preferences=None, num_items=50):
        """
        Get content-based recommendations
        """
        # Get user's order history
        user_orders = self._get_user_order_history(user_id)
        
        if not user_orders:
            return self._get_trending_items(num_items)
            
        # Find similar items to user's history
        recommendations = []
        for ordered_item in user_orders:
            item_idx = self.item_mapping[ordered_item['item_id']]
            similarities = self.similarity_matrix[item_idx]
            
            # Get top similar items
            similar_indices = similarities.argsort()[-20:][::-1]
            for idx in similar_indices:
                if idx != item_idx:  # Don't recommend same item
                    item_id = self.reverse_item_mapping[idx]
                    score = similarities[idx]
                    
                    recommendations.append({
                        'item_id': item_id,
                        'score': float(score),
                        'type': 'content_based',
                        'reason': f'Similar to {ordered_item["name"]}'
                    })
                    
        # Remove duplicates and sort by score
        seen = set()
        unique_recs = []
        for rec in sorted(recommendations, key=lambda x: x['score'], reverse=True):
            if rec['item_id'] not in seen:
                seen.add(rec['item_id'])
                unique_recs.append(rec)
                
        return unique_recs[:num_items]
```

### **Deep Learning Recommendation Model**

```python
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import (
    Input, Embedding, Dense, Dropout, Concatenate, 
    BatchNormalization, Lambda
)

class DeepRecommendationModel:
    def __init__(self, num_users, num_items, embedding_dim=128):
        self.num_users = num_users
        self.num_items = num_items
        self.embedding_dim = embedding_dim
        self.model = self._build_model()
        
    def _build_model(self):
        """
        Build neural collaborative filtering model
        """
        # User and item inputs
        user_input = Input(shape=(), name='user_id')
        item_input = Input(shape=(), name='item_id')
        
        # Context inputs
        time_input = Input(shape=(1,), name='time_features')
        location_input = Input(shape=(2,), name='location')
        weather_input = Input(shape=(1,), name='weather')
        
        # Embeddings
        user_embedding = Embedding(
            self.num_users, self.embedding_dim,
            name='user_embedding'
        )(user_input)
        item_embedding = Embedding(
            self.num_items, self.embedding_dim,
            name='item_embedding'
        )(item_input)
        
        # Flatten embeddings
        user_vec = Lambda(lambda x: tf.squeeze(x, axis=1))(user_embedding)
        item_vec = Lambda(lambda x: tf.squeeze(x, axis=1))(item_embedding)
        
        # Neural MF path
        mf_vector = Lambda(lambda x: x[0] * x[1])([user_vec, item_vec])
        
        # MLP path
        mlp_vector = Concatenate()([
            user_vec, item_vec, time_input, location_input, weather_input
        ])
        
        # Deep layers
        for units in [256, 128, 64]:
            mlp_vector = Dense(units, activation='relu')(mlp_vector)
            mlp_vector = BatchNormalization()(mlp_vector)
            mlp_vector = Dropout(0.2)(mlp_vector)
            
        # Combine MF and MLP
        combined = Concatenate()([mf_vector, mlp_vector])
        
        # Final prediction
        output = Dense(1, activation='sigmoid', name='rating')(combined)
        
        model = Model(
            inputs=[
                user_input, item_input, time_input, 
                location_input, weather_input
            ],
            outputs=output
        )
        
        model.compile(
            optimizer='adam',
            loss='binary_crossentropy',
            metrics=['mae', 'mse']
        )
        
        return model
    
    def prepare_training_data(self, interactions_df):
        """
        Prepare training data with features
        """
        X = {
            'user_id': interactions_df['user_id'].values,
            'item_id': interactions_df['item_id'].values,
            'time_features': self._extract_time_features(interactions_df),
            'location': interactions_df[['lat', 'lng']].values,
            'weather': interactions_df['weather_score'].values
        }
        
        # Create implicit feedback (1 for interaction, 0 for negative sampling)
        y = np.ones(len(interactions_df))
        
        # Add negative samples
        negative_samples = self._generate_negative_samples(interactions_df)
        for key in X:
            X[key] = np.concatenate([X[key], negative_samples[key]])
        y = np.concatenate([y, np.zeros(len(negative_samples['user_id']))])
        
        return X, y
    
    def _extract_time_features(self, df):
        """
        Extract time-based features
        """
        timestamps = pd.to_datetime(df['timestamp'])
        features = []
        
        for ts in timestamps:
            # Hour of day (normalized)
            hour_feature = ts.hour / 24.0
            
            # Day of week (weekend vs weekday)
            day_feature = 1.0 if ts.weekday() >= 5 else 0.0
            
            # Combine features
            time_feature = hour_feature + day_feature  # Simple combination
            features.append([time_feature])
            
        return np.array(features)
    
    def train(self, X, y, validation_split=0.2, epochs=50):
        """
        Train the deep learning model
        """
        self.model.fit(
            X, y,
            validation_split=validation_split,
            epochs=epochs,
            batch_size=1024,
            callbacks=[
                tf.keras.callbacks.EarlyStopping(
                    patience=5, restore_best_weights=True
                ),
                tf.keras.callbacks.ReduceLROnPlateau(
                    factor=0.5, patience=3
                )
            ]
        )
    
    def predict(self, user_id, context, candidate_items):
        """
        Get predictions for candidate items
        """
        X_pred = {
            'user_id': np.full(len(candidate_items), user_id),
            'item_id': candidate_items,
            'time_features': np.full((len(candidate_items), 1), 
                                   context['time_feature']),
            'location': np.full((len(candidate_items), 2), 
                              [context['lat'], context['lng']]),
            'weather': np.full(len(candidate_items), context['weather'])
        }
        
        predictions = self.model.predict(X_pred)
        
        recommendations = []
        for item_id, score in zip(candidate_items, predictions):
            recommendations.append({
                'item_id': item_id,
                'score': float(score[0]),
                'type': 'deep_learning'
            })
            
        return sorted(recommendations, key=lambda x: x['score'], reverse=True)
```

### **Context-Aware Model**

```python
class ContextAwareModel:
    def __init__(self):
        self.weather_api = WeatherService()
        self.traffic_api = TrafficService()
        self.event_calendar = EventCalendarService()
        
    def predict(self, user_id, context, num_items=50):
        """
        Generate context-aware recommendations
        """
        recommendations = []
        
        # Time-based recommendations
        time_recs = self._get_time_based_recommendations(
            user_id, context.get('current_time')
        )
        recommendations.extend(time_recs)
        
        # Weather-based recommendations
        weather_recs = self._get_weather_based_recommendations(
            user_id, context.get('location')
        )
        recommendations.extend(weather_recs)
        
        # Location-based recommendations
        location_recs = self._get_location_based_recommendations(
            user_id, context.get('location')
        )
        recommendations.extend(location_recs)
        
        # Event-based recommendations
        event_recs = self._get_event_based_recommendations(
            user_id, context.get('location'), context.get('current_time')
        )
        recommendations.extend(event_recs)
        
        # Remove duplicates and rank by relevance
        return self._rank_contextual_recommendations(recommendations)[:num_items]
    
    def _get_time_based_recommendations(self, user_id, current_time):
        """
        Recommend based on time of day/week
        """
        hour = current_time.hour
        day_of_week = current_time.weekday()
        
        recommendations = []
        
        # Breakfast items (6-11 AM)
        if 6 <= hour <= 11:
            breakfast_items = self._get_items_by_category(['breakfast', 'beverages'])
            for item in breakfast_items:
                recommendations.append({
                    'item_id': item['id'],
                    'score': 0.8,
                    'type': 'context_time',
                    'reason': 'Perfect for breakfast time'
                })
        
        # Lunch items (11 AM - 3 PM)
        elif 11 <= hour <= 15:
            lunch_items = self._get_items_by_category(['main_course', 'salads'])
            for item in lunch_items:
                recommendations.append({
                    'item_id': item['id'],
                    'score': 0.9,
                    'type': 'context_time',
                    'reason': 'Lunch special'
                })
        
        # Dinner items (6-11 PM)
        elif 18 <= hour <= 23:
            dinner_items = self._get_items_by_category(['main_course', 'appetizers'])
            for item in dinner_items:
                recommendations.append({
                    'item_id': item['id'],
                    'score': 0.85,
                    'type': 'context_time',
                    'reason': 'Dinner favorite'
                })
        
        # Weekend special recommendations
        if day_of_week >= 5:  # Weekend
            weekend_items = self._get_trending_weekend_items()
            for item in weekend_items:
                recommendations.append({
                    'item_id': item['id'],
                    'score': 0.7,
                    'type': 'context_time',
                    'reason': 'Weekend special'
                })
        
        return recommendations
    
    def _get_weather_based_recommendations(self, user_id, location):
        """
        Recommend based on weather conditions
        """
        try:
            weather = self.weather_api.get_current_weather(
                location['lat'], location['lng']
            )
            
            recommendations = []
            
            # Hot weather recommendations
            if weather['temperature'] > 35:  # Hot day
                cold_items = self._get_items_by_attributes(['cold', 'refreshing'])
                for item in cold_items:
                    recommendations.append({
                        'item_id': item['id'],
                        'score': 0.8,
                        'type': 'context_weather',
                        'reason': f'Perfect for hot weather ({weather["temperature"]}Â°C)'
                    })
            
            # Cold weather recommendations
            elif weather['temperature'] < 20:  # Cool day
                hot_items = self._get_items_by_attributes(['hot', 'warming', 'soup'])
                for item in hot_items:
                    recommendations.append({
                        'item_id': item['id'],
                        'score': 0.8,
                        'type': 'context_weather',
                        'reason': f'Warming for cool weather ({weather["temperature"]}Â°C)'
                    })
            
            # Rainy weather recommendations
            if weather.get('rain', 0) > 0:
                comfort_items = self._get_items_by_attributes(['comfort', 'warm'])
                for item in comfort_items:
                    recommendations.append({
                        'item_id': item['id'],
                        'score': 0.75,
                        'type': 'context_weather',
                        'reason': 'Comfort food for rainy day'
                    })
            
            return recommendations
            
        except Exception as e:
            logger.error(f"Weather API error: {e}")
            return []
```

## **2. Route Optimization AI**

### **Multi-Objective Route Optimization**

```python
from ortools.constraint_solver import routing_enums_pb2
from ortools.constraint_solver import pywrapcp
import googlemaps
import numpy as np

class DeliveryRouteOptimizer:
    def __init__(self, google_maps_api_key):
        self.gmaps = googlemaps.Client(key=google_maps_api_key)
        self.traffic_model = TrafficPredictionModel()
        
    def optimize_routes(self, driver_locations, delivery_orders, constraints):
        """
        Optimize delivery routes for multiple drivers
        """
        # Prepare data
        locations = self._prepare_locations(driver_locations, delivery_orders)
        distance_matrix = self._get_distance_matrix(locations)
        time_matrix = self._get_time_matrix(locations, constraints.get('traffic', True))
        
        # Create routing model
        manager = pywrapcp.RoutingIndexManager(
            len(locations),
            len(driver_locations),
            0  # Depot index
        )
        routing = pywrapcp.RoutingModel(manager)
        
        # Add distance constraint
        def distance_callback(from_index, to_index):
            from_node = manager.IndexToNode(from_index)
            to_node = manager.IndexToNode(to_index)
            return distance_matrix[from_node][to_node]
        
        transit_callback_index = routing.RegisterTransitCallback(distance_callback)
        routing.SetArcCostEvaluatorOfAllVehicles(transit_callback_index)
        
        # Add time windows constraint
        self._add_time_windows_constraint(routing, manager, time_matrix, delivery_orders)
        
        # Add capacity constraint (number of orders per driver)
        self._add_capacity_constraint(routing, manager, delivery_orders, constraints)
        
        # Set search parameters
        search_parameters = pywrapcp.DefaultRoutingSearchParameters()
        search_parameters.first_solution_strategy = (
            routing_enums_pb2.FirstSolutionStrategy.PATH_CHEAPEST_ARC
        )
        search_parameters.local_search_metaheuristic = (
            routing_enums_pb2.LocalSearchMetaheuristic.GUIDED_LOCAL_SEARCH
        )
        search_parameters.time_limit.FromSeconds(30)
        
        # Solve
        solution = routing.SolveWithParameters(search_parameters)
        
        if solution:
            return self._extract_routes(manager, routing, solution, locations, delivery_orders)
        else:
            # Fallback to greedy assignment
            return self._greedy_route_assignment(driver_locations, delivery_orders)
    
    def _get_time_matrix(self, locations, use_traffic=True):
        """
        Get time matrix considering real-time traffic
        """
        matrix = []
        
        for origin in locations:
            row = []
            for destination in locations:
                if origin == destination:
                    row.append(0)
                else:
                    travel_time = self._calculate_travel_time(
                        origin, destination, use_traffic
                    )
                    row.append(travel_time)
            matrix.append(row)
            
        return matrix
    
    def _calculate_travel_time(self, origin, destination, use_traffic):
        """
        Calculate travel time with traffic prediction
        """
        try:
            if use_traffic:
                # Use real-time traffic data
                result = self.gmaps.distance_matrix(
                    origins=[origin],
                    destinations=[destination],
                    mode="driving",
                    departure_time="now",
                    traffic_model="best_guess"
                )
                
                duration = result['rows'][0]['elements'][0]['duration_in_traffic']['value']
            else:
                # Use historical average
                result = self.gmaps.distance_matrix(
                    origins=[origin],
                    destinations=[destination],
                    mode="driving"
                )
                
                duration = result['rows'][0]['elements'][0]['duration']['value']
            
            return duration // 60  # Convert to minutes
            
        except Exception as e:
            logger.error(f"Error calculating travel time: {e}")
            # Fallback to straight-line distance estimation
            return self._estimate_travel_time_by_distance(origin, destination)
    
    def _add_time_windows_constraint(self, routing, manager, time_matrix, delivery_orders):
        """
        Add time window constraints for deliveries
        """
        def time_callback(from_index, to_index):
            from_node = manager.IndexToNode(from_index)
            to_node = manager.IndexToNode(to_index)
            return time_matrix[from_node][to_node]
        
        time_callback_index = routing.RegisterTransitCallback(time_callback)
        routing.AddDimension(
            time_callback_index,
            30,  # Allow waiting time
            180,  # Maximum time per route (3 hours)
            False,  # Don't force start cumul to zero
            "Time"
        )
        time_dimension = routing.GetDimensionOrDie("Time")
        
        # Add time windows for each order
        for order_idx, order in enumerate(delivery_orders):
            if order.get('time_window'):
                index = manager.NodeToIndex(order_idx + 1)  # +1 because depot is 0
                time_dimension.CumulVar(index).SetRange(
                    order['time_window']['start'],
                    order['time_window']['end']
                )
    
    def predict_delivery_time(self, restaurant_location, customer_address, current_time):
        """
        Predict accurate delivery time using ML
        """
        features = self._extract_delivery_features(
            restaurant_location, customer_address, current_time
        )
        
        # Use trained model to predict
        predicted_time = self.delivery_time_model.predict([features])[0]
        
        # Add confidence interval
        confidence = self.delivery_time_model.predict_confidence([features])[0]
        
        return {
            'estimated_time_minutes': int(predicted_time),
            'confidence_interval': {
                'min': int(predicted_time - confidence),
                'max': int(predicted_time + confidence)
            },
            'confidence_score': float(confidence)
        }
    
    def _extract_delivery_features(self, restaurant_location, customer_address, current_time):
        """
        Extract features for delivery time prediction
        """
        # Distance features
        distance = self._calculate_distance(restaurant_location, customer_address)
        
        # Time features
        hour = current_time.hour
        day_of_week = current_time.weekday()
        is_weekend = day_of_week >= 5
        
        # Traffic features
        traffic_factor = self._get_traffic_factor(current_time)
        
        # Weather features
        weather = self._get_weather_conditions(restaurant_location)
        
        # Historical features
        avg_delivery_time = self._get_historical_avg_delivery_time(
            restaurant_location, customer_address
        )
        
        return [
            distance,
            hour,
            day_of_week,
            int(is_weekend),
            traffic_factor,
            weather['temperature'],
            weather['rain_probability'],
            avg_delivery_time
        ]
```

## **3. Menu Optimization AI**

### **Dynamic Pricing Model**

```python
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
import pandas as pd

class MenuOptimizationAI:
    def __init__(self):
        self.demand_model = DemandPredictionModel()
        self.pricing_model = DynamicPricingModel()
        self.competitor_analyzer = CompetitorAnalyzer()
        self.profit_optimizer = ProfitOptimizer()
        
    def optimize_menu_pricing(self, restaurant_id, menu_items, historical_data):
        """
        Optimize menu item pricing for maximum profit
        """
        recommendations = []
        
        for item in menu_items:
            # Predict demand at different price points
            demand_predictions = self._predict_demand_curve(item, historical_data)
            
            # Analyze competitor pricing
            competitor_prices = self.competitor_analyzer.get_competitor_prices(
                item['name'], item['category']
            )
            
            # Calculate optimal price
            optimal_price = self._calculate_optimal_price(
                item, demand_predictions, competitor_prices
            )
            
            # Generate recommendation
            recommendation = {
                'item_id': item['id'],
                'current_price': item['price'],
                'recommended_price': optimal_price,
                'expected_demand_change': self._calculate_demand_change(
                    item['price'], optimal_price, demand_predictions
                ),
                'expected_revenue_change': self._calculate_revenue_change(
                    item, optimal_price, demand_predictions
                ),
                'confidence': self._calculate_confidence(item, historical_data),
                'reasoning': self._generate_pricing_reasoning(
                    item, optimal_price, competitor_prices
                )
            }
            
            recommendations.append(recommendation)
        
        return recommendations
    
    def predict_item_demand(self, item_id, features):
        """
        Predict demand for a menu item given various features
        """
        # Features: time_of_day, day_of_week, weather, season, price, promotions, etc.
        prediction = self.demand_model.predict([features])
        
        return {
            'predicted_orders': int(prediction[0]),
            'demand_category': self._categorize_demand(prediction[0]),
            'confidence_interval': self.demand_model.predict_confidence([features])[0]
        }
    
    def suggest_menu_items(self, restaurant_id, season='current'):
        """
        Suggest new menu items based on trends and gaps
        """
        # Analyze current menu performance
        current_performance = self._analyze_current_menu(restaurant_id)
        
        # Identify market gaps
        market_gaps = self._identify_market_gaps(restaurant_id)
        
        # Analyze trending items
        trending_items = self._get_trending_items(season)
        
        # Generate suggestions
        suggestions = []
        
        for gap in market_gaps:
            if gap['category'] in trending_items:
                suggestion = {
                    'category': gap['category'],
                    'suggested_items': trending_items[gap['category']],
                    'market_opportunity': gap['opportunity_score'],
                    'competition_level': gap['competition_level'],
                    'recommended_price_range': gap['price_range'],
                    'reasoning': f"High demand in {gap['category']} with low competition"
                }
                suggestions.append(suggestion)
        
        return suggestions
    
    def optimize_menu_placement(self, restaurant_id, menu_items):
        """
        Optimize menu item placement and categorization
        """
        # Analyze item performance
        performance_data = self._get_item_performance_data(restaurant_id)
        
        # Calculate menu engineering matrix (profitability vs popularity)
        menu_matrix = self._calculate_menu_matrix(menu_items, performance_data)
        
        recommendations = []
        
        for item in menu_items:
            matrix_position = menu_matrix[item['id']]
            
            if matrix_position['category'] == 'star':
                recommendation = {
                    'item_id': item['id'],
                    'action': 'highlight',
                    'placement': 'featured_section',
                    'reasoning': 'High profit, high popularity - promote heavily'
                }
            elif matrix_position['category'] == 'plow_horse':
                recommendation = {
                    'item_id': item['id'],
                    'action': 'increase_price',
                    'placement': 'standard',
                    'reasoning': 'Popular but low profit - increase price or reduce costs'
                }
            elif matrix_position['category'] == 'puzzle':
                recommendation = {
                    'item_id': item['id'],
                    'action': 'promote',
                    'placement': 'special_offers',
                    'reasoning': 'High profit but low popularity - needs promotion'
                }
            else:  # dog
                recommendation = {
                    'item_id': item['id'],
                    'action': 'remove_or_redesign',
                    'placement': 'hidden',
                    'reasoning': 'Low profit and popularity - consider removal'
                }
            
            recommendations.append(recommendation)
        
        return recommendations

class DemandPredictionModel:
    def __init__(self):
        self.model = RandomForestRegressor(
            n_estimators=100,
            max_depth=10,
            random_state=42
        )
        self.scaler = StandardScaler()
        self.feature_names = [
            'hour_of_day', 'day_of_week', 'is_weekend', 'is_holiday',
            'temperature', 'rain_probability', 'season',
            'price', 'discount_percentage', 'is_featured',
            'competitor_avg_price', 'restaurant_rating',
            'historical_avg_demand', 'trend_score'
        ]
        
    def prepare_training_data(self, orders_df, weather_df, menu_df):
        """
        Prepare training data for demand prediction
        """
        features = []
        targets = []
        
        # Group orders by item and time period
        grouped = orders_df.groupby(['menu_item_id', 'date']).agg({
            'quantity': 'sum',
            'total_amount': 'sum'
        }).reset_index()
        
        for _, row in grouped.iterrows():
            item_features = self._extract_item_features(
                row['menu_item_id'], row['date'], weather_df, menu_df
            )
            features.append(item_features)
            targets.append(row['quantity'])
        
        X = np.array(features)
        y = np.array(targets)
        
        # Scale features
        X_scaled = self.scaler.fit_transform(X)
        
        return X_scaled, y
    
    def train(self, X, y):
        """
        Train the demand prediction model
        """
        self.model.fit(X, y)
        
        # Calculate feature importance
        feature_importance = dict(zip(
            self.feature_names, 
            self.model.feature_importances_
        ))
        
        return feature_importance
    
    def predict(self, features):
        """
        Predict demand for given features
        """
        features_scaled = self.scaler.transform([features])
        prediction = self.model.predict(features_scaled)
        return prediction
    
    def predict_confidence(self, features):
        """
        Predict with confidence interval using ensemble variance
        """
        features_scaled = self.scaler.transform([features])
        
        # Get predictions from all trees
        tree_predictions = [
            tree.predict(features_scaled)[0] 
            for tree in self.model.estimators_
        ]
        
        # Calculate confidence based on prediction variance
        std = np.std(tree_predictions)
        confidence = 1.0 / (1.0 + std)
        
        return confidence
```

## **4. Multilingual AI Chatbot**

### **Conversational AI Architecture**

```python
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import torch
from datetime import datetime
import re

class MomFoodChatbot:
    def __init__(self):
        # Load pre-trained multilingual models
        self.ar_model = AutoModelForSeq2SeqLM.from_pretrained(
            "aubmindlab/bert-base-arabic-camelbert-da"
        )
        self.en_model = AutoModelForSeq2SeqLM.from_pretrained(
            "microsoft/DialoGPT-medium"
        )
        
        self.intent_classifier = IntentClassifier()
        self.entity_extractor = EntityExtractor()
        self.context_manager = ContextManager()
        self.knowledge_base = KnowledgeBase()
        
    def process_message(self, message, user_id, language='auto'):
        """
        Process incoming chat message and generate response
        """
        # Detect language if not specified
        if language == 'auto':
            language = self._detect_language(message)
        
        # Extract intent and entities
        intent = self.intent_classifier.classify(message, language)
        entities = self.entity_extractor.extract(message, language)
        
        # Get conversation context
        context = self.context_manager.get_context(user_id)
        
        # Generate response based on intent
        response = self._generate_response(
            intent, entities, context, language
        )
        
        # Update context
        self.context_manager.update_context(
            user_id, message, response, intent, entities
        )
        
        return response
    
    def _detect_language(self, text):
        """
        Detect if text is Arabic or English
        """
        arabic_chars = re.findall(r'[\u0600-\u06FF]', text)
        english_chars = re.findall(r'[a-zA-Z]', text)
        
        if len(arabic_chars) > len(english_chars):
            return 'ar'
        else:
            return 'en'
    
    def _generate_response(self, intent, entities, context, language):
        """
        Generate appropriate response based on intent
        """
        if intent['category'] == 'order_status':
            return self._handle_order_status_query(entities, context, language)
        elif intent['category'] == 'menu_inquiry':
            return self._handle_menu_inquiry(entities, context, language)
        elif intent['category'] == 'complaint':
            return self._handle_complaint(entities, context, language)
        elif intent['category'] == 'recommendation':
            return self._handle_recommendation_request(entities, context, language)
        elif intent['category'] == 'delivery_inquiry':
            return self._handle_delivery_inquiry(entities, context, language)
        else:
            return self._generate_general_response(intent, entities, language)
    
    def _handle_order_status_query(self, entities, context, language):
        """
        Handle order status inquiries
        """
        order_number = entities.get('order_number')
        
        if not order_number and context.get('current_order'):
            order_number = context['current_order']['number']
        
        if order_number:
            # Get order status from database
            order_status = self._get_order_status(order_number)
            
            if language == 'ar':
                if order_status['status'] == 'preparing':
                    return f"Ø·Ù„Ø¨Ùƒ Ø±Ù‚Ù… {order_number} Ù‚ÙŠØ¯ Ø§Ù„ØªØ­Ø¶ÙŠØ± ÙÙŠ Ø§Ù„Ù…Ø·Ø¹Ù…. Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ Ù„Ù„ØªØ³Ù„ÙŠÙ… Ù‡Ùˆ {order_status['estimated_delivery']}."
                elif order_status['status'] == 'on_the_way':
                    return f"Ø·Ù„Ø¨Ùƒ Ø±Ù‚Ù… {order_number} ÙÙŠ Ø§Ù„Ø·Ø±ÙŠÙ‚ Ø¥Ù„ÙŠÙƒ. Ø§Ù„Ø³Ø§Ø¦Ù‚ {order_status['driver_name']} Ø³ÙŠØµÙ„ Ø®Ù„Ø§Ù„ {order_status['eta']} Ø¯Ù‚ÙŠÙ‚Ø©."
                elif order_status['status'] == 'delivered':
                    return f"ØªÙ… ØªÙˆØµÙŠÙ„ Ø·Ù„Ø¨Ùƒ Ø±Ù‚Ù… {order_number} Ø¨Ù†Ø¬Ø§Ø­. Ù†ØªÙ…Ù†Ù‰ Ø£Ù† ØªÙƒÙˆÙ† Ù‚Ø¯ Ø§Ø³ØªÙ…ØªØ¹Øª Ø¨ÙˆØ¬Ø¨ØªÙƒ!"
            else:
                if order_status['status'] == 'preparing':
                    return f"Your order #{order_number} is being prepared at the restaurant. Estimated delivery time is {order_status['estimated_delivery']}."
                elif order_status['status'] == 'on_the_way':
                    return f"Your order #{order_number} is on the way! Driver {order_status['driver_name']} will arrive in {order_status['eta']} minutes."
                elif order_status['status'] == 'delivered':
                    return f"Your order #{order_number} has been delivered successfully. Hope you enjoyed your meal!"
        else:
            if language == 'ar':
                return "Ù…Ù† ÙØ¶Ù„Ùƒ Ù‚Ø¯Ù… Ø±Ù‚Ù… Ø§Ù„Ø·Ù„Ø¨ Ø­ØªÙ‰ Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ Ù…Ø¹Ø±ÙØ© Ø­Ø§Ù„Ø© Ø·Ù„Ø¨Ùƒ."
            else:
                return "Please provide your order number so I can help you track your order status."
    
    def _handle_menu_inquiry(self, entities, context, language):
        """
        Handle menu-related questions
        """
        restaurant_name = entities.get('restaurant_name')
        food_type = entities.get('food_type')
        dietary_restriction = entities.get('dietary_restriction')
        
        if restaurant_name:
            menu_items = self._get_restaurant_menu(restaurant_name, language)
            
            if dietary_restriction:
                menu_items = self._filter_by_dietary_restriction(
                    menu_items, dietary_restriction
                )
            
            if language == 'ar':
                response = f"Ù‚Ø§Ø¦Ù…Ø© Ø·Ø¹Ø§Ù… {restaurant_name}:\n"
                for item in menu_items[:5]:  # Show top 5 items
                    response += f"â€¢ {item['name_ar']} - {item['price']} Ø±ÙŠØ§Ù„\n"
                response += "\nÙ‡Ù„ ØªØ±ÙŠØ¯ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø¹Ù† Ø£ÙŠ Ù…Ù† Ù‡Ø°Ù‡ Ø§Ù„Ø£Ø·Ø¨Ø§Ù‚ØŸ"
            else:
                response = f"{restaurant_name} menu:\n"
                for item in menu_items[:5]:
                    response += f"â€¢ {item['name']} - {item['price']} SAR\n"
                response += "\nWould you like more details about any of these dishes?"
            
            return response
        
        elif food_type:
            restaurants = self._find_restaurants_by_food_type(food_type, language)
            
            if language == 'ar':
                response = f"Ø§Ù„Ù…Ø·Ø§Ø¹Ù… Ø§Ù„ØªÙŠ ØªÙ‚Ø¯Ù… {food_type}:\n"
                for restaurant in restaurants[:3]:
                    response += f"â€¢ {restaurant['name_ar']} - ØªÙ‚ÙŠÙŠÙ… {restaurant['rating']}\n"
            else:
                response = f"Restaurants serving {food_type}:\n"
                for restaurant in restaurants[:3]:
                    response += f"â€¢ {restaurant['name']} - Rating {restaurant['rating']}\n"
            
            return response
    
    def _handle_recommendation_request(self, entities, context, language):
        """
        Handle recommendation requests using AI
        """
        user_id = context.get('user_id')
        location = entities.get('location') or context.get('location')
        cuisine_preference = entities.get('cuisine')
        budget = entities.get('budget')
        
        # Get AI recommendations
        recommendations = self._get_ai_recommendations(
            user_id, location, cuisine_preference, budget
        )
        
        if language == 'ar':
            response = "Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªÙØ¶ÙŠÙ„Ø§ØªÙƒ ÙˆØ·Ù„Ø¨Ø§ØªÙƒ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©ØŒ Ø£Ù†ØµØ­Ùƒ Ø¨Ù€:\n"
            for rec in recommendations[:3]:
                response += f"â€¢ {rec['name_ar']} Ù…Ù† {rec['restaurant_ar']} - {rec['reason_ar']}\n"
            response += "\nÙ‡Ù„ ØªØ±ÙŠØ¯ Ø£Ù† Ø£Ø³Ø§Ø¹Ø¯Ùƒ ÙÙŠ Ø·Ù„Ø¨ Ø£ÙŠ Ù…Ù† Ù‡Ø°Ù‡ Ø§Ù„Ø§Ù‚ØªØ±Ø§Ø­Ø§ØªØŸ"
        else:
            response = "Based on your preferences and order history, I recommend:\n"
            for rec in recommendations[:3]:
                response += f"â€¢ {rec['name']} from {rec['restaurant']} - {rec['reason']}\n"
            response += "\nWould you like me to help you order any of these suggestions?"
        
        return response

class IntentClassifier:
    def __init__(self):
        self.intents = {
            'order_status': {
                'ar': ['Ø­Ø§Ù„Ø© Ø§Ù„Ø·Ù„Ø¨', 'ÙˆÙŠÙ† Ø·Ù„Ø¨ÙŠ', 'Ù…ØªÙ‰ ÙŠÙˆØµÙ„', 'ØªØªØ¨Ø¹ Ø§Ù„Ø·Ù„Ø¨'],
                'en': ['order status', 'track order', 'where is my order', 'delivery time']
            },
            'menu_inquiry': {
                'ar': ['Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø·Ø¹Ø§Ù…', 'Ø§ÙŠØ´ Ø¹Ù†Ø¯ÙƒÙ…', 'Ø§Ù„Ø£ÙƒÙ„ Ø§Ù„Ù…ØªÙˆÙØ±', 'Ø§Ù„Ù…Ù†ÙŠÙˆ'],
                'en': ['menu', 'what do you have', 'food options', 'available dishes']
            },
            'recommendation': {
                'ar': ['Ø§Ù‚ØªØ±Ø­ Ù„ÙŠ', 'Ø§ÙŠØ´ ØªÙ†ØµØ­Ù†ÙŠ', 'Ø£ÙØ¶Ù„ Ø£ÙƒÙ„Ø©', 'ÙˆØ´ Ø£Ø·Ù„Ø¨'],
                'en': ['recommend', 'suggest', 'what should i order', 'best dish']
            },
            'complaint': {
                'ar': ['Ø´ÙƒÙˆÙ‰', 'Ù…Ø´ÙƒÙ„Ø©', 'ØºÙŠØ± Ø±Ø§Ø¶ÙŠ', 'Ø§Ù„Ø£ÙƒÙ„ Ø³ÙŠØ¡'],
                'en': ['complaint', 'problem', 'issue', 'bad food', 'not satisfied']
            }
        }
    
    def classify(self, message, language):
        """
        Classify user intent from message
        """
        message_lower = message.lower()
        
        for intent, keywords in self.intents.items():
            for keyword in keywords.get(language, []):
                if keyword in message_lower:
                    return {
                        'category': intent,
                        'confidence': 0.8,
                        'detected_keywords': [keyword]
                    }
        
        # Default intent if no match
        return {
            'category': 'general_inquiry',
            'confidence': 0.3,
            'detected_keywords': []
        }
```

## **5. AI Performance Monitoring**

### **Model Performance Tracking**

```python
import mlflow
import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score

class AIPerformanceMonitor:
    def __init__(self):
        mlflow.set_tracking_uri("http://localhost:5000")
        self.experiment_name = "momfood_ai_models"
        mlflow.set_experiment(self.experiment_name)
        
    def track_recommendation_performance(self, model_name, predictions, actuals):
        """
        Track recommendation model performance
        """
        with mlflow.start_run(run_name=f"{model_name}_evaluation"):
            # Calculate metrics
            hit_rate = self._calculate_hit_rate(predictions, actuals)
            ndcg = self._calculate_ndcg(predictions, actuals)
            diversity = self._calculate_diversity(predictions)
            
            # Log metrics
            mlflow.log_metric("hit_rate", hit_rate)
            mlflow.log_metric("ndcg", ndcg)
            mlflow.log_metric("diversity", diversity)
            
            # Log model
            mlflow.sklearn.log_model(model_name, "model")
            
            return {
                'hit_rate': hit_rate,
                'ndcg': ndcg,
                'diversity': diversity
            }
    
    def track_route_optimization_performance(self, optimized_routes, actual_delivery_times):
        """
        Track route optimization accuracy
        """
        with mlflow.start_run(run_name="route_optimization_evaluation"):
            # Calculate metrics
            time_accuracy = self._calculate_time_prediction_accuracy(
                optimized_routes, actual_delivery_times
            )
            distance_efficiency = self._calculate_distance_efficiency(optimized_routes)
            
            mlflow.log_metric("time_prediction_accuracy", time_accuracy)
            mlflow.log_metric("distance_efficiency", distance_efficiency)
            
            return {
                'time_accuracy': time_accuracy,
                'distance_efficiency': distance_efficiency
            }
    
    def monitor_chatbot_performance(self, conversations):
        """
        Monitor chatbot effectiveness
        """
        with mlflow.start_run(run_name="chatbot_evaluation"):
            # Calculate metrics
            intent_accuracy = self._calculate_intent_accuracy(conversations)
            resolution_rate = self._calculate_resolution_rate(conversations)
            user_satisfaction = self._calculate_user_satisfaction(conversations)
            
            mlflow.log_metric("intent_accuracy", intent_accuracy)
            mlflow.log_metric("resolution_rate", resolution_rate)
            mlflow.log_metric("user_satisfaction", user_satisfaction)
            
            return {
                'intent_accuracy': intent_accuracy,
                'resolution_rate': resolution_rate,
                'user_satisfaction': user_satisfaction
            }
    
    def generate_ai_performance_report(self):
        """
        Generate comprehensive AI performance report
        """
        experiments = mlflow.search_experiments()
        
        report = {
            'timestamp': datetime.now().isoformat(),
            'models': {},
            'overall_health': 'healthy'
        }
        
        for experiment in experiments:
            runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])
            
            for _, run in runs.iterrows():
                model_name = run['tags.mlflow.runName']
                metrics = {
                    metric.replace('metrics.', ''): value 
                    for metric, value in run.items() 
                    if metric.startswith('metrics.')
                }
                
                report['models'][model_name] = {
                    'metrics': metrics,
                    'status': self._assess_model_health(metrics),
                    'last_updated': run['end_time']
                }
        
        return report
```

This comprehensive AI integration architecture provides the foundation for building intelligent features that enhance user experience, optimize operations, and drive business growth for the MomFood platform.